{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f00260df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Only log error messages\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467cf503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of the dataset you want to split as train and test\n",
    "TRAIN_TEST_SPLIT = 0.1\n",
    "\n",
    "MAX_INPUT_LENGTH = 1024  # Maximum length of the input to the model\n",
    "MIN_TARGET_LENGTH = 5  # Minimum length of the output by the model\n",
    "MAX_TARGET_LENGTH = 128  # Maximum length of the output by the model\n",
    "#MAX_TARGET_LENGTH = 400\n",
    "BATCH_SIZE = 8  # Batch-size for training our model\n",
    "LEARNING_RATE = 2e-5  # Learning-rate for training our model\n",
    "MAX_EPOCHS = 1  # Maximum number of epochs we will train the model for\n",
    "\n",
    "# This notebook is built on the t5-small checkpoint from the Hugging Face Model Hub\n",
    "#MODEL_CHECKPOINT = \"t5-small\"\n",
    "MODEL_CHECKPOINT = \"facebook/bart-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcfd1dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at ./t5_small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"./t5_small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7785ff6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "270aa56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6064c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_CHECKPOINT in [\"t5-small\", \"t5-base\", \"t5-large\", \"t5-3b\", \"t5-11b\"]:\n",
    "    prefix = \"summarize: \"              #for tokenizer and model\n",
    "else:\n",
    "    prefix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "435479bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example = \"Fresh shelling from Ukraine rocked Belgorod overnight, the governor said in a video posted Sunday morning, as Russian dissidents ramp up pressure on the western border region.Gov. Vyacheslav Gladkov said there had been Ukrainian attacks in several locations under his administration.`The night was rather turbulent,` Gladkov said. `There is a lot of destruction. There is no information about casualties.`Due to the violence, 4,000 people are being housed in temporary accommodations. Children in the area are being moved to a camp in Crimea for their own safety, Gladkov added.Dissidents appear near shelled area: Also Sunday, the Freedom for Russia Legion, one of two dissident Russian units fighting under Ukrainian command, posted a video which they said showed their fighters on the streets of a village on the outskirts of Shebekino, one of the areas Gladkov said was attacked.The footage appeared to show the legion in Novaya Tavolzhanka, according to geolocation by CNN, and groups of people moving through the streets as a unit.“We’re going in! The advance assault group of the Legion and the Russian Volunteer Corp entering the suburb of Shebekino,” the group said in the clip's caption.CNN cannot verify the legion’s claim, but the video’s release will be seen as a further attempt to destabilize Russia in the information space as well as disrupting its military plans.Meetings requested: In another bold move, the legion posted a video in which its leader and that of a second dissident group, the Russian Volunteer Corps, request a meeting with Gladkov. In exchange, they offered to release two Russian soldiers allegedly in their custody.The video shows the purported soldiers giving their names and those of their hometowns in Russia. The dissident leaders -- who have made no secret of their opposition to Russian President Vladimir Putin -- say they want to talk to Gladkov about the fate of the country and the war. No threat is made to the lives of the men they are holding.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24e9a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_pref = prefix + example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "908fb70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = tokenizer(example_pref, max_length=MAX_INPUT_LENGTH, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6a9fc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"MG Rover's proposed tie-up with Chinese carmaker Shanghai Automotive could result in 3,000 jobs being lost if the deal goes ahead, according to the Financial Times.\"}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer, framework=\"tf\")\n",
    "\n",
    "summarizer(\n",
    "    example,\n",
    "    min_length=MIN_TARGET_LENGTH,\n",
    "    max_length=MAX_TARGET_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6578fc65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
